name: Deploy to Argo CD on EKS
on:
 workflow_dispatch:

permissions:
      id-token: write   # This is required for requesting the JWT
      contents: write
      
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v2
  
    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
         role-to-assume: arn:aws:iam::${{ secrets.ACCOUNT_ID }}:role/${{ secrets.ROLE_NAME }}
         aws-region: ${{ secrets.REGION }}

    - name: Retrieve an EKS endpoint 
      run: |
        eks_endpoint=$(aws eks describe-cluster --name MyEKSCluster --query "cluster.endpoint" --output text)
        echo "EKS_Endpoint=$eks_endpoint" >> $GITHUB_ENV
        
    - name: Update an EKS endpoint in a yaml file and create a update script
      run: | 
        echo "sed -i 's|server: .*|server: $EKS_Endpoint|' my-app-argo-app.yaml" > update_script.sh

    - name: Get matching image tags 
      run: |
        output=$(aws ecr-public describe-images --repository-name my_repo_xgboost_test --region us-east-1)
        matching_images=$(echo "$output" | jq -r '.imageDetails[].imageTags[] | select(endswith("_xgboost"))')
        echo "IMAGE_TAG=$matching_images" >> $GITHUB_ENV
        
    - name: Update a docker image in a yaml file and update the update script
      run: | 
        echo "sed -i 's|value: .*|value: public.ecr.aws/v3z5t7a3/my_repo_xgboost_test:$IMAGE_TAG|' my-app-argo-app.yaml" >> update_script.sh

    - name: Print update script content
      run: |
        echo "Contents of update_script.sh:"
        cat update_script.sh
    
    - name: Get Bastion Host Public IP
      id: bastion_ip
      run: |
        bastion_ip=$(aws cloudformation describe-stacks --stack-name BastionHostStack --query "Stacks[0].Outputs[?OutputKey=='BastionPublicIP'].OutputValue" --output text)
        echo "::set-output name=ip::$bastion_ip"

    - name: Create SSH key file
      run: |
        echo "${{ secrets.SSH_KEY }}" > key.pem
        chmod 600 key.pem

    - name: SSH to Bastion host and load a yaml file 
      env:
         BASTION_IP: ${{ steps.bastion_ip.outputs.ip }}
      run: | 
        ssh -o StrictHostKeyChecking=no -i key.pem ec2-user@$BASTION_IP "
          if [ -f /home/ec2-user/my-app-argo-app.yaml ]; then
            echo 'File exists. Deleting...'
            rm /home/ec2-user/my-app-argo-app.yaml
          else
            echo 'File does not exist. Proceeding to upload...'
          fi
          wget https://raw.githubusercontent.com/ruihukuang/Argo_Helm_Xgboost_EKS/main/my-app-argo-app.yaml
        "

    - name: SSH to Bastion Host and Update Kubeconfig
      env:
        BASTION_IP: ${{ steps.bastion_ip.outputs.ip }}
      run: |
        ssh -o StrictHostKeyChecking=no -i key.pem ec2-user@$BASTION_IP "
          if [ -f /home/ec2-user/update_script.sh ]; then
            echo 'update_script.sh exists. Deleting...'
            rm /home/ec2-user/update_script.sh
          else
            echo 'update_script.sh does not exist. Proceeding to copy...'
          fi"
        scp -o StrictHostKeyChecking=no -i key.pem update_script.sh ec2-user@$BASTION_IP:/home/ec2-user/
        ssh -o StrictHostKeyChecking=no -i key.pem ec2-user@$BASTION_IP << EOF
        set -ex  # Enable command tracing and exit on error
        sudo rm -rf /home/ec2-user/cluster_ip.txt
        sudo rm -rf /home/ec2-user/patch_output.txt
        sudo rm -rf /home/ec2-user/hostname.txt
        sudo rm -rf /home/ec2-user/secret.txt
        sudo rm -rf /home/ec2-user/get_helm.sh
        aws eks update-kubeconfig --region ${{ secrets.REGION }} --name MyEKSCluster
        kubectl get nodes || { echo "Failed to get nodes"; exit 1; }

        # Install metrics-server
        # Check if metrics-server exists in kube-system
        if ! kubectl get deployment metrics-server -n kube-system &> /dev/null; then
          echo "metrics-server not found. Installing metrics-server..."
  
          # Attempt to install metrics-server
          kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml || { 
            echo "Failed to install metrics-server"; 
            exit 1; 
          }

          echo "metrics-server installation initiated."
        else
          echo "metrics-server already exists in kube-system."
        fi 
      
        # Show metrics
        # Number of attempts
        max_attempts=10

        # Counter for attempts
        attempt=1

        # Loop to check readiness
        while [ $attempt -le $max_attempts ]; do
          echo "Checking readiness of metrics-server (Attempt \$attempt/\$max_attempts)..."
  
          # Check if metrics-server has at least one ready replica
          if kubectl get deployment metrics-server -n kube-system -o jsonpath='{.status.readyReplicas}' | grep -q '1'; then
            echo "metrics-server is ready."
            exit 0
          else
            echo "metrics-server not ready. Retrying in 30 seconds..."
            sleep 30
          fi 
          # Increment the attempt counter
          attempt=\$((attempt + 1))
        done || { echo "metrics-server not ready"; exit 1; }
          
        kubectl top nodes || { echo "Failed to show node metrics"; exit 1; }
        kubectl top pods --all-namespaces || { echo "Failed to show pod metrics"; exit 1; }
      
        if ! kubectl get namespace argocd; then
          kubectl create namespace argocd || { echo "Failed to create namespace argocd"; exit 1; }
        else
          echo "Namespace argocd already exists"
          kubectl delete namespace argocd || { echo "Failed to delete namespace argocd"; exit 1; }
          kubectl create namespace argocd || { echo "Failed to create namespace argocd after deleting this namespace"; exit 1; }
        fi
      
        if ! kubectl get namespace my-app-test; then
          kubectl create namespace my-app-test || { echo "Failed to create namespace my-app-test"; exit 1; }
        else
          echo "Namespace my-app-test already exists"
          kubectl delete namespace my-app-test || { echo "Failed to delete namespace my-app-test"; exit 1; }
          kubectl create namespace my-app-test || { echo "Failed to create namespace my-app-test after deleting this namespace"; exit 1; }
        fi
      
        sudo chmod +x /home/ec2-user/update_script.sh
        sudo bash /home/ec2-user/update_script.sh || { echo "Failed to execute update_script.sh"; exit 1; }
      
        echo "Contents of my-app-argo-app.yaml:"
        sudo cat /home/ec2-user/my-app-argo-app.yaml || { echo "Failed to read my-app-argo-app.yaml"; exit 1; }
      
        # Install Argo CLI
        # Check if Argo CLI exists
        if ! command -v argocd &> /dev/null; then
          echo "Argo CLI not found. Installing Argo CLI..."
  
          # Download and install Argo CLI
          sudo curl -sSL -o /usr/local/bin/argocd https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
  
          # Make it executable
          sudo chmod +x /usr/local/bin/argocd || { 
            echo "Failed to install Argo CLI"; 
          exit 1; 
         }
  
          echo "Argo CLI installed successfully."
        else
          echo "Argo CLI already exists."
        fi
      
        # Install Helm
        # Check if Helm is installed
        if ! command -v helm &> /dev/null; then
          echo "Helm not found. Installing Helm..."
  
          # Download the Helm installation script
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
  
          # Make the script executable
          sudo chmod 700 get_helm.sh
  
           # Run the installation script
           ./get_helm.sh || { 
           echo "Failed to install Helm"; 
           exit 1; 
          }
  
          echo "Helm installed successfully."
        else
          echo "Helm is already installed."
        fi
      
        # Add the Argo CD Helm Repository
        # Check if the Helm repo "argo" exists
        if ! helm repo list | grep -q 'argo'; then
          echo "Helm repo 'argo' not found. Adding repo..."
  
          # Add the Helm repo
          helm repo add argo https://argoproj.github.io/argo-helm
  
          # Update the Helm repo
          helm repo update || { 
            echo "Failed to update Helm repo"; 
            exit 1; 
          }
  
          echo "Helm repo 'argo' added successfully."
        else
          echo "Helm repo 'argo' already exists."
        fi
      
        # Install Argo CD Using Helm
        # Check if Argo CD is installed using Helm
        if ! helm list -n argocd | grep -q 'argocd'; then
          echo "Argo CD not found. Installing Argo CD..."
  
          # Install Argo CD using Helm
          helm install argocd argo/argo-cd --namespace argocd --create-namespace || { 
            echo "Failed to install Argo CD"; 
            exit 1; 
          }
  
          echo "Argo CD installed successfully."
        else
          echo "Argo CD is already installed."
        fi
      
        # Wait for argocd-server deployment to be ready
        echo "Waiting for argocd-server deployment to be ready..."
        for i in {1..60}; do
          if kubectl get deployment argocd-server -n argocd -o jsonpath='{.status.readyReplicas}' | grep -q '1'; then
            echo "argocd-server deployment is ready"
            break
          else
            echo "Waiting for argocd-server deployment to be ready... (Attempt \$i)"
            sleep 10
          fi
        done || { echo "argocd-server deployment not ready after waiting"; exit 1; }

        # Wait for argocd-server service to be ready
        # Run the command in the background and redirect output to a file
        kubectl get svc argocd-server -n argocd -o jsonpath='{.spec.clusterIP}' > cluster_ip.txt &

        # Capture the process ID (PID) of the background job
        KUBECTL_PID=$!

        # Optionally, you can wait for the background process to complete
        wait $KUBECTL_PID

        # Check the exit status of the background process
        if [ $? -eq 0 ]; then
          echo "Command to check if a cluster ip exists succeeded."
        else
          echo "Command to check if a cluster ip exists failed."
          exit 1
        fi

        # Check if the file exists and is not empty 10 times and sleep 30 seconds each time
        for attempt in {1..10}; do
          if [ -s cluster_ip.txt ]; then
            echo 'cluster_ip.txt has content. Displaying contents:'
            cat cluster_ip.txt
            break
          else
            echo 'cluster_ip.txt is empty or does not exist. Retrying in 30 seconds... (Attempt $attempt)'
            sleep 30
          fi
        done
        
        # Expose Argo CD API Server via an AWS Load Balancer
        # Attempt to patch the service
        echo "Attempting to patch svc argocd-server to LoadBalancer..."
        # Run the kubectl patch command in the background and redirect output to a file
        kubectl patch svc argocd-server -n argocd --type='merge' -p '{"spec": {"type": "LoadBalancer"}}' > patch_output.txt 2>&1 &

        # Capture the process ID (PID) of the background job
        PATCH_PID=$!

        # Optionally, wait for the background process to complete
        wait $PATCH_PID

        # Check the exit status of the background process
        if [ $? -eq 0 ]; then
          echo "Patch command executed successfully."
          # Optionally, display the output from the file
          cat patch_output.txt
        else
          echo "Patch command failed."
          # Display the error output from the file
          cat patch_output.txt
        fi
        
        # Check if the file exists and is not empty 10 times and sleep 30 seconds each time
        for attempt in {1..10}; do
          if [ -s patch_output.txt ]; then
            echo 'patch_output.txt has content. Displaying contents:'
            cat patch_output.txt
            break
          else
            echo 'patch_output.txt is empty or does not exist. Retrying in 30 seconds... (Attempt $attempt)'
            sleep 30
          fi
        done

        kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' > hostname.txt
        
        a=\$(kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
        echo \"The hostname is: \$a\"

        b=\$(ssh -o StrictHostKeyChecking=no -i key.pem ec2-user@$BASTION_IP "
        kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'
        ")
        echo "The hostname after ssh is: \$b"

        REGION=${{ secrets.REGION }}

        echo $REGION
        
        sudo sed -i "s/\*\*\*/$REGION/" hostname.txt
        
        # Access the Argo CD UI and get the password
        kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d > secret.txt
      
        # Log into Argo with an original password
        argocd login \$(cat /home/ec2-user/hostname.txt) --username admin --password \$(cat /home/ec2-user/secret.txt) --insecure || { echo "Failed to login to Argo"; exit 1; } 
      
        # Update password in Argo CD
        argocd account update-password --current-password \$(cat /home/ec2-user/secret.txt) --new-password ${{ secrets.ARGOCD_NEW_PASSWORD }} || { echo "Failed to update Argo password"; exit 1; }
      
        # Log into Argo with a new password
        argocd login \$(cat /home/ec2-user/hostname.txt) --username admin --password ${{ secrets.ARGOCD_NEW_PASSWORD }} || { echo "Failed to login with new Argo password"; exit 1; }
      
        # Retrieve the name of the current Kubernetes context
        ContextName=\$(kubectl config current-context) || { echo "Failed to get Kubernetes context"; exit 1; }
      
        # Add a cluster into Argo
        sudo argocd cluster add \$ContextName --yes || { echo "Failed to add cluster to Argo"; exit 1; }
      
        # Apply Argo CD Application
        kubectl apply -f /home/ec2-user/my-app-argo-app.yaml || { echo "Failed to apply Argo CD application"; exit 1; }
      

        EOF
